<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Socially Responsible and Trustworthy Foundation Models Workshop @ NeurIPS 2025</title>
  <link rel="stylesheet" href="style.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Source+Serif+4:opsz,wght@8..60,400..700&display=swap" rel="stylesheet">
</head>
<body>
<header>
  <div class="header-content">
    <h1>Socially Responsible and Trustworthy Foundation Models (ResponsibleFM)</h1>
    <div class="subtitle">NeurIPS 2025 Workshop ¬∑ Hilton Mexico City Reforma</div>
    <nav>
      <a href="#about">About</a>
      <a href="#topics">Topics</a>
      <a href="#schedule">Schedule</a>
      <a href="#speakers">Invited Speakers</a>
      <a href="#organizers">Organizers</a>
      <a href="#call">Call for Papers</a>
      <a href="#committee">Committee</a>
    </nav>
  </div>
</header>

<main>
  <section id="about">
    <h2>About</h2>
    <div class="content-wrapper">
      <p>
        The ResponsibleFM Workshop at NeurIPS 2025 is an interdisciplinary forum focused on advancing ethical, inclusive, and socially responsible research in foundation models (including language and multimodal models). With the increasing impact of foundation models on society, the workshop aims to proactively address ethical, social, and safety risks‚Äîintegrating fairness, accountability, transparency, and safety into every phase of model development and deployment.
      </p>
      <p>
        ResponsibleFM brings together researchers, practitioners, ethicists, policy-makers, and affected communities to catalyze new methodologies, frameworks, and best practices that ensure foundation model research serves the common good.
      </p>
    </div>
  </section>

  <section id="topics">
    <h2>Topics</h2>
    <div class="content-wrapper">
      <ul>
        <li>
          <b>Defining and Measuring Trustworthiness:</b>
          <br>
          <ul>
            <li>Developing rigorous definitions of trustworthiness in foundation models, considering factors such as fairness, safety, truthfulness, privacy, explainability, robustness, and cultural awareness.</li>
            <li>Standardizing evaluation protocols and sharing best practices for reproducible and transparent trustworthiness assessment.</li>
          </ul>
        </li>
        <li>
          <b>Techniques to Enhance Trustworthiness:</b>
          <br>
          <ul>
            <li>Methods for mitigating bias and enhancing fairness in both pre-training and fine-tuning stages.</li>
            <li>Knowledge editing, continual learning, and machine unlearning for correcting or removing undesirable model behaviors or information.</li>
            <li>Model watermarking and provenance tracking to support accountability and traceability.</li>
            <li>Defenses against adversarial attacks and jailbreaking, including robust training, safety layers, and red-teaming methodologies.</li>
          </ul>
        </li>
        <li>
          <b>Deployment Challenges and Applications for Social Good:</b>
          <br>
          <ul>
            <li>Case studies of deploying foundation models in real-world scenarios such as healthcare, education, public policy, social welfare, and environmental monitoring.</li>
            <li>Addressing the unique risks of high-stakes applications and methods for maximizing positive societal impact.</li>
          </ul>
        </li>
        <li>
          <b>Datasets and Benchmarks for Trustworthiness:</b>
          <br>
          <ul>
            <li>Design, creation, and curation of datasets that reflect diversity, inclusivity, and ethical considerations, with attention to sensitive domains (e.g., healthcare, finance, legal).</li>
            <li>Establishing comprehensive benchmarks for evaluating fairness, bias, robustness, privacy, and other trustworthiness aspects.</li>
            <li>Exploring dataset documentation, transparency (data cards, datasheets), and issues of data consent and representation.</li>
          </ul>
        </li>
        <li>
          <b>Interdisciplinary Perspectives and Governance:</b>
          <br>
          <ul>
            <li>Insights from social sciences, philosophy, law, and public policy on the development and deployment of foundation models.</li>
            <li>Legal and ethical frameworks for responsible AI research, including compliance, auditability, and regulatory challenges.</li>
            <li>Participatory and community-engaged approaches for inclusive decision-making and risk assessment.</li>
            <li>Model governance, transparency in decision processes (e.g., model and data cards), and mechanisms for accountability.</li>
          </ul>
        </li>
      </ul>
    </div>
  </section>
  

  <section id="schedule">
    <h2>Schedule</h2>
    <div class="content-wrapper">
      <ul class="timeline">
        <li><b>09:00‚Äì09:10</b> Opening remarks</li>
        <li><b>09:10‚Äì10:40</b> Keynote speeches</li>
        <li><b>10:40‚Äì11:30</b> Spotlight session</li>
        <li><b>11:30‚Äì12:30</b> Poster session</li>
        <li><b>12:30‚Äì13:30</b> Student mentoring lunch</li>
        <li><b>13:30‚Äì15:00</b> Keynote speeches</li>
        <li><b>15:00‚Äì15:50</b> Panel discussion</li>
        <li><b>15:50‚Äì16:50</b> Oral paper session</li>
        <li><b>16:50‚Äì17:20</b> Best Paper & Outstanding Paper presentation</li>
        <li><b>17:20‚Äì17:30</b> Closing remarks</li>
      </ul>
    </div>
  </section>

  <section id="speakers">
    <h2>Invited Speakers</h2>
    <div class="speakers-list">
      <div class="speaker-card">
        <div class="speaker-image">
          <img src="images/yoshuabengio.png" alt="Yoshua Bengio" loading="lazy">
        </div>
        <div class="speaker-info">
          <b>Yoshua Bengio</b>
          <span class="affiliation">Universit√© de Montr√©al, Mila</span>
          <div class="topic">Safety and Social Impact of Frontier Foundation Models</div>
        </div>
      </div>
      <div class="speaker-card">
        <div class="speaker-image">
          <img src="images/Kush.jpeg" alt="Kush R. Varshney" loading="lazy">
        </div>
        <div class="speaker-info">
          <b>Kush R. Varshney</b>
          <span class="affiliation">IBM Research</span>
          <div class="topic">Responsible and Trustworthy Foundation Models in Industry</div>
        </div>
      </div>
      <div class="speaker-card">
        <div class="speaker-image">
          <img src="images/diyiyang.jpg" alt="Diyi Yang" loading="lazy">
        </div>
        <div class="speaker-info">
          <b>Diyi Yang</b>
          <span class="affiliation">Stanford University</span>
          <div class="topic">Social-aware Foundation Models</div>
        </div>
      </div>
      <div class="speaker-card">
        <div class="speaker-image">
          <img src="images/HimabinduLakkaraju.png" alt="Himabindu Lakkaraju" loading="lazy">
        </div>
        <div class="speaker-info">
          <b>Himabindu Lakkaraju</b>
          <span class="affiliation">Harvard University</span>
          <div class="topic">Interpretability and Trustworthy Foundation Models</div>
        </div>
      </div>
      <div class="speaker-card">
        <div class="speaker-image">
          <img src="images/AylinCaliskan.png" alt="Aylin Caliskan" loading="lazy">
        </div>
        <div class="speaker-info">
          <b>Aylin Caliskan</b>
          <span class="affiliation">University of Washington</span>
          <div class="topic">Fairness of Foundation Models</div>
        </div>
      </div>
      <div class="speaker-card">
        <div class="speaker-image">
          <img src="images/SanmiKoyejo.jpg" alt="Sanmi Koyejo" loading="lazy">
        </div>
        <div class="speaker-info">
          <b>Sanmi Koyejo</b>
          <span class="affiliation">Stanford University</span>
          <div class="topic">Principled Understanding of Trustworthy Foundation Models</div>
        </div>
      </div>
    </div>
  </section>

  <section id="organizers">
    <h2>Organizers</h2>
    <div class="organizer-list">
      <div class="organizer-card">
        <div class="organizer-image">
          <img src="images/canyuchen.jpg" alt="Canyu Chen" loading="lazy">
        </div>
        <div class="organizer-info">
          <b>Canyu Chen</b>
          <span class="affiliation">Northwestern University</span>
        </div>
      </div>
      <div class="organizer-card">
        <div class="organizer-image">
          <img src="images/yuehuang.jpg" alt="Yue Huang" loading="lazy">
        </div>
        <div class="organizer-info">
          <b>Yue Huang</b>
          <span class="affiliation">University of Notre Dame</span>
        </div>
      </div>
      <div class="organizer-card">
        <div class="organizer-image">
          <img src="images/mohit.png" alt="Mohit Bansal" loading="lazy">
        </div>
        <div class="organizer-info">
          <b>Mohit Bansal</b>
          <span class="affiliation">UNC Chapel Hill</span>
        </div>
      </div>
      <div class="organizer-card">
        <div class="organizer-image">
          <img src="images/yejinchoi.png" alt="Yejin Choi" loading="lazy">
        </div>
        <div class="organizer-info">
          <b>Yejin Choi</b>
          <span class="affiliation">Stanford University</span>
        </div>
      </div>
      <div class="organizer-card">
        <div class="organizer-image">
          <img src="images/Dawnsong.jpg" alt="Dawn Song" loading="lazy">
        </div>
        <div class="organizer-info">
          <b>Dawn Song</b>
          <span class="affiliation">UC Berkeley</span>
        </div>
      </div>
      <div class="organizer-card">
        <div class="organizer-image">
          <img src="images/manlingli.jpg" alt="Manling Li" loading="lazy">
        </div>
        <div class="organizer-info">
          <b>Manling Li</b>
          <span class="affiliation">Northwestern University & Stanford University</span>
        </div>
      </div>
    </div>
  </section>

  <section id="call">
    <h2>Call for Papers / Submission</h2>
    <div class="content-wrapper">
      <div class="important-dates">
        <div class="date-item">
          <b>Submission Site:</b>
          <a href="https://openreview.net/" target="_blank" rel="noopener noreferrer">OpenReview</a> (details TBA)
        </div>
        <div class="date-item"><b>Key dates (AoE):</b></div>
        <div class="date-item">üóìÔ∏è Submission Oct 31</div>
        <div class="date-item">‚úÖ Notification Nov 7</div>
        <div class="date-item">üìù Camera ready Nov 23</div>
        <div class="date-item">üìç Workshop date will be posted later</div>
      </div>
      <p class="submission-note">Submissions are double-blind, follow NeurIPS 2025 format, and are non-archival.</p>
      <p class="submission-note">Awards: We will select one Best Paper and one Outstanding Paper.</p>
    </div>
  </section>

  <section id="committee">
    <h2>Program Committee</h2>
    <div class="content-wrapper">
      <p>
        The program committee includes over 70 researchers and practitioners worldwide. A full list will be announced soon.
      </p>
    </div>
  </section>
</main>

<footer>
  <div class="footer-content">
    &copy; 2025 Socially Responsible and Trustworthy Foundation Models Workshop &middot; NeurIPS 2025
  </div>
</footer>
</body>
</html>
